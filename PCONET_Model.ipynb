{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "import shutil\n",
        "import glob\n",
        "import zipfile\n",
        "import cv2"
      ],
      "metadata": {
        "id": "mmxwTc-oOheU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "FxjTQ3IwOryb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "ROOT_DIR = '/content/gdrive/MyDrive/PCOS/train'\n",
        "number_of_images = {}\n",
        "for dir in os.listdir(ROOT_DIR):\n",
        "   number_of_images[dir] = len(os.listdir(os.path.join(ROOT_DIR, dir)))\n",
        "   print(\"\", dir, \"\", number_of_images[dir])\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Define a function for data augmentation and preprocessing\n",
        "def preprocess_data(path, split):\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/PCOS/train' + path):\n",
        "        os.mkdir(\"/content/gdrive/MyDrive/PCOS/train\" + path)\n",
        "\n",
        "        for dir in os.listdir(ROOT_DIR):\n",
        "            os.makedirs(\"/content/gdrive/MyDrive/PCOS/train\" + path + \"/\" + dir)\n",
        "            for img in np.random.choice(a=os.listdir(os.path.join(ROOT_DIR, dir)), size=(math.floor(split * number_of_images[dir]) - 5), replace=False):\n",
        "                O = os.path.join(ROOT_DIR, dir, img)\n",
        "                D = os.path.join(\"/content/gdrive/MyDrive/PCOS/train\" + path, dir)\n",
        "                shutil.copy(O, D)\n",
        "\n",
        "    else:\n",
        "        print(\"Folder already exists\")\n",
        "\n",
        "# Preprocess the data\n",
        "preprocess_data('train', 0.7)\n",
        "preprocess_data(\"val\", 0.15)\n",
        "preprocess_data(\"test\", 0.15)\n",
        "\n",
        "# Define functions for data loading and preprocessing\n",
        "def preprocessingImage1(path):\n",
        "    image_data = ImageDataGenerator(\n",
        "        zoom_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        preprocessing_function=preprocess_input,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "    image = image_data.flow_from_directory(\n",
        "        directory=path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "    return image\n",
        "\n",
        "def preprocessionfImage2(path):\n",
        "    image_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "    image = image_data.flow_from_directory(\n",
        "        directory=path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "    return image\n",
        "\n",
        "# Load and preprocess the data\n",
        "path = '/content/gdrive/MyDrive/PCOS/train'\n",
        "train_data = preprocessingImage1(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/PCOS/traintest'\n",
        "test_data = preprocessionfImage2(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/PCOS/trainval'\n",
        "val_data = preprocessionfImage2(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7d_gwoxO6E_",
        "outputId": "7cd8f698-b24f-422d-dcbf-990061518666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            " infected  781\n",
            " notinfected  1143\n",
            "Folder already exists\n",
            "Folder already exists\n",
            "Folder already exists\n",
            "Found 1924 images belonging to 2 classes.\n",
            "Found 278 images belonging to 2 classes.\n",
            "Found 278 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "SbrEn5h_PVEB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6dscAhoL07q",
        "outputId": "8b2ab353-9c86-463e-ca84-a77bb4afc000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 111, 111, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 394272)            0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 124)               48889852  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 124)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               32000     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,923,005\n",
            "Trainable params: 48,923,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "61/61 [==============================] - 713s 12s/step - loss: 0.4346 - accuracy: 0.7937 - val_loss: 0.2272 - val_accuracy: 0.9245\n",
            "Epoch 2/10\n",
            "61/61 [==============================] - 242s 4s/step - loss: 0.2989 - accuracy: 0.8857 - val_loss: 0.1504 - val_accuracy: 0.9604\n",
            "Epoch 3/10\n",
            "61/61 [==============================] - 229s 4s/step - loss: 0.2178 - accuracy: 0.9200 - val_loss: 0.1414 - val_accuracy: 0.9856\n",
            "Epoch 4/10\n",
            "61/61 [==============================] - 228s 4s/step - loss: 0.1871 - accuracy: 0.9345 - val_loss: 0.1049 - val_accuracy: 0.9892\n",
            "Epoch 5/10\n",
            "61/61 [==============================] - 246s 4s/step - loss: 0.1582 - accuracy: 0.9475 - val_loss: 0.1119 - val_accuracy: 0.9856\n",
            "Epoch 6/10\n",
            "61/61 [==============================] - 232s 4s/step - loss: 0.1352 - accuracy: 0.9537 - val_loss: 0.0607 - val_accuracy: 0.9892\n",
            "Epoch 7/10\n",
            "61/61 [==============================] - 245s 4s/step - loss: 0.1155 - accuracy: 0.9678 - val_loss: 0.0575 - val_accuracy: 0.9964\n",
            "Epoch 8/10\n",
            "61/61 [==============================] - 227s 4s/step - loss: 0.1007 - accuracy: 0.9751 - val_loss: 0.1370 - val_accuracy: 0.9496\n",
            "Epoch 9/10\n",
            "61/61 [==============================] - 225s 4s/step - loss: 0.0980 - accuracy: 0.9673 - val_loss: 0.1065 - val_accuracy: 0.9784\n",
            "Epoch 10/10\n",
            "61/61 [==============================] - 243s 4s/step - loss: 0.0915 - accuracy: 0.9751 - val_loss: 0.0374 - val_accuracy: 0.9964\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ed23ae442b0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Define the input layer\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Convolutional blocks\n",
        "x = Conv2D(32, (3, 3), activation='relu', strides=1, padding='valid')(inputs)\n",
        "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "\n",
        "# Convolutional block 2\n",
        "x = Conv2D(32, (3, 3), activation='relu', strides=1, padding='valid')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "\n",
        "# Convolutional block 3\n",
        "x = Conv2D(64, (3, 3), activation='relu', strides=1, padding='valid')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "\n",
        "# Convolutional block 4\n",
        "x = Conv2D(64, (3, 3), activation='relu', strides=1, padding='valid')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "\n",
        "# Convolutional block 5\n",
        "x = Conv2D(128, (3, 3), activation='relu', strides=1, padding='valid')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "\n",
        "# Flatten the output\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Dense layers\n",
        "x = Dense(124, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "\n",
        "# Output layer for binary classification\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "# Define callbacks\n",
        "mc = ModelCheckpoint(filepath=\"bestmodel.h5\", monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "es = EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5, verbose=1)\n",
        "cb = [mc, es]\n",
        "\n",
        "learning_rate = 0.00001\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'], run_eagerly=True)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(train_data, epochs=10, batch_size=16, validation_data=val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model"
      ],
      "metadata": {
        "id": "7LSKJMkkPrur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = model.predict(test_data)\n",
        "y_pred = np.round(y_pred)\n",
        "\n",
        "# Get the true labels\n",
        "y_true = test_data.labels\n",
        "\n",
        "# Display Classification Report and Confusion Matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "print(\"Confusion Matrix: \")\n",
        "print(confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ9WwSnZORo3",
        "outputId": "a0d69a84-f6bf-48a7-fddd-34d579389971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 84s 10s/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.38      0.38       112\n",
            "           1       0.58      0.59      0.59       166\n",
            "\n",
            "    accuracy                           0.50       278\n",
            "   macro avg       0.48      0.48      0.48       278\n",
            "weighted avg       0.50      0.50      0.50       278\n",
            "\n",
            "Confusion Matrix: \n",
            "[[42 70]\n",
            " [68 98]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}