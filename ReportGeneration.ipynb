{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilNOtHa6o10Y",
        "outputId": "eeea312b-652d-434b-f9f4-278e528eb670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 10411 images belonging to 2 classes.\n",
            "Found 2602 images belonging to 2 classes.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_reparameterization_1  (None, 240, 240, 8)      12304     \n",
            "  (Conv2DReparameterization)                                     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 238, 238, 32)      2336      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 119, 119, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 119, 119, 32)      0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 117, 117, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 58, 58, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 58, 58, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 28, 28, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 50176)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               25690624  \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_reparameterization_1   (None, 2)                2052      \n",
            " (DenseReparameterization)                                       \n",
            "                                                                 \n",
            " one_hot_categorical_1 (OneH  ((None, 2),              0         \n",
            " otCategorical)               (None, 2))                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,735,060\n",
            "Trainable params: 25,735,060\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "326/326 [==============================] - 4441s 14s/step - loss: 2.0948 - accuracy: 0.7757 - val_loss: 2.1621 - val_accuracy: 0.8847\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_probability as tfp\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TensorFlow Probability layers and distributions\n",
        "tfpl = tfp.layers\n",
        "tfd = tfp.distributions\n",
        "\n",
        "# Setup the dataset\n",
        "data_dir = '/content/drive/MyDrive/PCOS_formatted'\n",
        "img_height, img_width = 256, 256\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Divergence function for Bayesian layers\n",
        "divergence_fn = lambda q, p, _: tfd.kl_divergence(q, p) / train_generator.samples\n",
        "\n",
        "# Build the Bayesian CNN model\n",
        "model_bayes = Sequential([\n",
        "    tfpl.Convolution2DReparameterization(input_shape=(255,255, 3),\n",
        "                                          filters=8, kernel_size=16, activation='relu',\n",
        "                                          kernel_prior_fn=tfpl.default_multivariate_normal_fn,\n",
        "                                          kernel_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
        "                                          kernel_divergence_fn=divergence_fn,\n",
        "                                          bias_prior_fn=tfpl.default_multivariate_normal_fn,\n",
        "                                          bias_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
        "                                          bias_divergence_fn=divergence_fn),\n",
        "    Conv2D(32, (3,3), activation='relu'),\n",
        "     MaxPooling2D(2,2),\n",
        "    Dropout(0.28),\n",
        "    Conv2D(32, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Dropout(0.28),\n",
        "  #  Conv2D(64, (3,3), activation='relu'),\n",
        "  #  MaxPooling2D(2,2),\n",
        "  #  Dropout(0.15),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Dropout(0.28),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.28),\n",
        "    tfpl.DenseReparameterization(units=tfpl.OneHotCategorical.params_size(2), activation=None,\n",
        "                                 kernel_prior_fn=tfpl.default_multivariate_normal_fn,\n",
        "                                 kernel_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
        "                                 kernel_divergence_fn=divergence_fn,\n",
        "                                 bias_prior_fn=tfpl.default_multivariate_normal_fn,\n",
        "                                 bias_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
        "                                 bias_divergence_fn=divergence_fn\n",
        "                                ),\n",
        "    tfpl.OneHotCategorical(2)\n",
        "])\n",
        "model_bayes.summary()\n",
        "\n",
        "# Compile the model\n",
        "def negative_log_likelihood(y_true, y_pred):\n",
        "    return -y_pred.log_prob(y_true)\n",
        "\n",
        "model_bayes.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0025),\n",
        "                    loss=negative_log_likelihood,\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "epochs = 1  # You can adjust this based on your requirements\n",
        "\n",
        "history = model_bayes.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "loss, accuracy = model_bayes.evaluate(validation_generator, verbose=1)\n",
        "print(f\"Validation Loss: {loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import  cv2\n",
        "\n",
        "# 1. Probability Plot for a Given Image\n",
        "\n",
        "def plot_image_probabilities(model, image_path):\n",
        "    # Load and preprocess the image\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_height, img_width))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = img_array / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Predict the image\n",
        "    predictions = model(img_array)\n",
        "\n",
        "    # Extract probabilities\n",
        "    probs = predictions.mean().numpy()[0]\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar([0, 1], probs, color=['blue', 'red'])\n",
        "    plt.xticks([0, 1], ['Not Infected', 'Infected'])\n",
        "    plt.ylabel('Probability')\n",
        "    plt.title('Prediction Probabilities')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SJOMToSXpEYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab\n",
        "\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Function to predict and gather information for a single image\n",
        "def predict_and_gather_info(model, image_path):\n",
        "    try:\n",
        "        # Load and preprocess the image\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.resize(img, (255, 255))  # Resize the image to match the model's input shape\n",
        "        img = img / 255.0  # Normalize the image\n",
        "\n",
        "        # Make the image compatible with the model's input shape\n",
        "        img_array = np.expand_dims(img, axis=0)\n",
        "\n",
        "        # Predict the image\n",
        "        predictions = model(img_array)\n",
        "\n",
        "        # Extract probabilities\n",
        "        probs = predictions.mean().numpy()[0]\n",
        "\n",
        "        return img, probs\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Function to create a bar chart and save it as an image\n",
        "def create_bar_chart(probs, image_filename):\n",
        "    labels = ['Not Infected', 'Infected']\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.bar(labels, probs)\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Probability')\n",
        "    plt.title('Prediction Probabilities')\n",
        "    plt.savefig(image_filename, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# Loop through the first 10 images in the training dataset\n",
        "for i in range(10000, 10010):\n",
        "    # Create a new PDF document for each image\n",
        "    pdf_filename = f\"automatic_report_{i}.pdf\"\n",
        "    c = canvas.Canvas(pdf_filename, pagesize=letter)\n",
        "\n",
        "    # Add a title to the report\n",
        "    c.setFont(\"Helvetica-Bold\", 18)\n",
        "    c.drawString(100, 750, f\"Automatic Report for Image {i}\")\n",
        "\n",
        "    image_path = f\"/content/drive/MyDrive/PCOS_formatted/infected/image_{i}.jpg\"  # Adjust the path accordingly\n",
        "\n",
        "    # Predict and gather information for the image\n",
        "    image, probabilities = predict_and_gather_info(model_bayes, image_path)\n",
        "\n",
        "    # Create and save the bar chart as an image\n",
        "    bar_chart_filename = f\"bar_chart_{i}.png\"\n",
        "    create_bar_chart(probabilities, bar_chart_filename)\n",
        "\n",
        "    # Add the image to the report\n",
        "    c.drawImage(image_path, 100, 450, width=300, height=300)\n",
        "\n",
        "    # Add the bar chart to the report\n",
        "    c.drawImage(bar_chart_filename, 100, 150, width=400, height=200)\n",
        "\n",
        "    # Add information to the report\n",
        "    c.setFont(\"Helvetica\", 12)\n",
        "    c.drawString(100, 400, \"Predictions:\")\n",
        "    c.drawString(100, 380, f\"Not Infected Probability: {probabilities[0]:.4f}\")\n",
        "    c.drawString(100, 360, f\"Infected Probability: {probabilities[1]:.4f}\")\n",
        "\n",
        "    # Save and close the PDF for this image\n",
        "    c.save()\n",
        "\n",
        "    print(f\"Automatic report for Image {i} generated and saved as {pdf_filename}.\")\n"
      ],
      "metadata": {
        "id": "Xz3sQumcE80I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbb4c84-ae7a-4f5c-96f9-1937bf770e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reportlab\n",
            "  Downloading reportlab-4.0.4-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/1.9 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (9.4.0)\n",
            "Installing collected packages: reportlab\n",
            "Successfully installed reportlab-4.0.4\n",
            "Automatic report for Image 10000 generated and saved as automatic_report_10000.pdf.\n",
            "Automatic report for Image 10001 generated and saved as automatic_report_10001.pdf.\n",
            "Automatic report for Image 10002 generated and saved as automatic_report_10002.pdf.\n",
            "Automatic report for Image 10003 generated and saved as automatic_report_10003.pdf.\n",
            "Automatic report for Image 10004 generated and saved as automatic_report_10004.pdf.\n",
            "Automatic report for Image 10005 generated and saved as automatic_report_10005.pdf.\n",
            "Automatic report for Image 10006 generated and saved as automatic_report_10006.pdf.\n",
            "Automatic report for Image 10007 generated and saved as automatic_report_10007.pdf.\n",
            "Automatic report for Image 10008 generated and saved as automatic_report_10008.pdf.\n",
            "Automatic report for Image 10009 generated and saved as automatic_report_10009.pdf.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRSKPcuLYDTm",
        "outputId": "65210cbf-0c41-49a2-83ec-32153f3840f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF report 'automatic_report.pdf' is located in the current directory: /content\n"
          ]
        }
      ]
    }
  ]
}